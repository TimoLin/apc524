\documentclass[11pt]{article}
%\usepackage{fullpage}[margin=1in]
\usepackage{array}
\usepackage{graphicx}
\usepackage{amssymb, amsmath}
\usepackage{hyperref}
\usepackage{textcomp}
\usepackage[labelfont=bf]{caption}
\begin{document}


\title{\textbf{Tabulation of Chemical Source Terms for Turbulent
    Combustion Simulations}}

\author{Emmet Cleary: emcleary@princeton.edu \and Daniel Floryan:
  dfloryan@princeton.edu \and Jeffry Lew: jklew@princeton.edu \and
  Bruce Perry: bperry@princeton.edu \and Emre Turkoz:
  eturkoz@princeton.edu} 

%\date{January 11th, 2015 }
\maketitle

\section{Introduction}
Turbulent combustion simulations require closure of chemical source
terms (reaction rates). This is not trivial, as the chemical source
terms follow highly nonlinear Arrhenius kinetics and can depend on
numerous stiffly-coupled chemical reactions. One approach, rather than
evaluating these terms on the fly, is to calculate a set of
thermochemical states \textit{a priori} and use these when solving
conservation equations. When used with flamelet models\footnote{Pierce
  \textit{et al.}, J. Fluid Mech. (2004) vol. 504, pp. 73-97.},
chemical source term tabulation greatly reduces computational cost of
large eddy simulations (LES) of turbulent reacting flows.

The challenge with these tabulation methods is determining the source
term for statistics generated by the LES.  This is done by tabulating
source terms against a predetermined variable. The trick is to select
a single variable that uniquely identifies each thermochemical
state. Temperature is the most obvious one: the more a reaction
proceeds, the more heat is released. However, filtering the energy
conservation equation for LES leads to a closure problem. It is much
simpler to filter species conservation equations, but a single
chemical species is usually insufficient to identify the
thermochemical state uniquely. Rather, one must take a linear
combination of several species, called a progress variable, to define
a mass-based conservation equation that is suitable for turbulent
combustion simulations. Once a progress variable is chosen, the
thermochemical states can be sorted, convoluted with a probability
density function (PDF) to calculate filtered quantities for LES, and
interpolated as needed to generate a table for chemical source terms
(a “chemtable”) on a predefined grid.

\begin{figure} [h]
\centering
\includegraphics[width=\textwidth]{scope}
\caption{\label{fig:overview} Context of project in relation to existing research codes.}
\label{fig:codes}
\end{figure}

Our project uses outputs from an existing research code called
FlameMaster to facilitate and automate the selection of progress
variables (see Fig.~\ref{fig:codes}). Our project also processes
FlameMaster data to create a chemtable through sorting based on the
selected progress variable, convolution, and interpolation. This
chemtable can be used by the existing NGA codes to perform LES. A
variety of interpolation schemes, integration methods, and PDFs are
incorporated into the code to ensure that it is easily adaptable. The
automated selection of progress variable has not been implemented in
any existing code. Furthermore, although codes exist to create
chemtables after the progress variable has been defined, they lack
generality and must be rewritten or substantially modified for
different problems. A modular program for this task developed with 
well-defined interfaces will significantly improve the generality and
usability of the chemtable code.

\section{Design Process}
The design process for this project began with identifying
deficiencies in existing combustion research codes used by the
Computational Reacting Turbulent Flow Laboratory (CTRFL). We identified
several routines that could be modular: sorting, integrating,
interpolating, and PDFs. Next, we outlined the overall process of our
software by drawing flowcharts (Fig.~\ref{fig:flow1} and
~\ref{fig:flow2}). This helped structure our interfaces, as the
flowcharts were used to identify inputs and outputs of the various
routines. 
% During the process of determining the steps of our program, we
% deliberated “make versus buy” decisions.
Then, we designed polymorphic classes in C++. This language choice was
determined largely by our experience, but also for the ease of
parallelization using OpenMP.
%After identifying which routines could take advantage of polymorphism,
%we examined the strengths of programming languages covered during
%lectures and decided that C++ was best for data processing and
%computation-heavy functions that may be parallelized.  
Python was selected to provide the user interface with C++ functions,
since it is well-suited to processing text inputs. Because our
interfaces were well-designed before writing our code, only a few
minor changes were made to the interfaces during software development.
Specifics on the tools used during the design process (such as for
testing and profiling) are provided in the “Architecture” section.  I
was also important to evaluate the pros and cons of writing our own
codes rather than us existing codes. This is discussed below.


%Increasing the amount of functionality by intermediate milestones has
%presented us the opportunity to receive feedback from the class and
%improve future iterations of our program as well as ensure our project
%can achieve its core goals. 



\subsection{Make vs. Buy}
Many routines required for our program exist in external libraries
(e.g. interpolators, integrators, PDFs). The decision to write
original code versus use libraries was determined by the simplicity
of routine, our interfaces, and the expected effect on run time.

For simple integrators and interpolators, original codes were
written. Some of the more complicated routines (e.g. quadrature
integration or Hermite interpolation) use orthogonal polynomials that
are far more challenging to write and test, so the external library
AlgLib\footnote{www.alglib.net} was used.

Interfaces posed a slight problem for the PDFs. In our design review,
it was suggested that we use external libraries to calculate values
for the Beta PDF. This could have worked if we calculated PDF values
on the fly during convolution. Instead, our approach required knowing
full distributions over a range of statistics. It was far easier to
calculate numerous PDF values at once and store them in a matrix.

Original routines had negligible influence on the total
run time (see Profiling). There would have been negligible benefit
to using better-optimized code.
 
\section{Architecture}
Our project consists of two connected parts: progress variable
determination (Fig.~\ref{fig:flow1}) and chemtable generation
(Fig.~\ref{fig:flow2}). Our program is written in C++ and Python 2.7. 
%SWIG is used to
%interface the C++ functions with Python. Python 2.7 will be used. 
The following tools are used during software development:

\begin{itemize}
\item SWIG for interfacing C++ with Python
\item Python Unittest framework for testing
\item Doxygen for documentation
\item Git for version control
\item Valgrind for memory leak detection
\item cProfile for profiling
\end{itemize}

\begin{figure} [h]
\centering
\includegraphics[width=\textwidth]{diagram_1_shortened_v4}
\caption{\label{fig:flow1} Flowchart for progress variable selection. Boxes are color-coded by programming language and task distribution}
\end{figure}

\begin{figure} [h]
\centering
\includegraphics[width=\textwidth]{diagram_2_shortened_v4}
\caption{\label{fig:flow2} Flowchart for generating the chemtables, using the progress variable  determined by the first section of code. Boxes are color-coded by programming language and task distribution.}
\end{figure}

\subsection{Progress Variable, $C$}
As shown in Fig.~\ref{fig:flow1}, inputs to the progress variable
section of our program include a text input file containing the user\textquotesingle s
selection of options to be used at run time and many combustion
data files containing thermochemical state information. The final
output of this section is the best progress variable, which is
passed to the table generation section of our program in
Fig.~\ref{fig:flow2}. Detailed descriptions of the processes in
Fig.~\ref{fig:flow1} are below.

\begin{enumerate} 
\item The text input file contains a user-specified stoichiometric
  mixture fraction value, a user-specified list of species mass
  fractions, and options for function implementations. All
  combinations of mass fractions in the user-specified list are
  candidates for the progress variable. Data files are the FlameMaster
  data, containing thermochemical states represented as columns of
  temperature, species mass fraction, and chemical source terms in
  mixture fraction space.
\item Python code exports two rows from each data file to
  be interpolated at the stoichiometric mixture fraction.
\item Python code calculates all progress variable candidates using
  these interpolated values.
\item C++ code sorts all progress variables by the stoichiometric
  temperature, generating a matrix of temperature and all progress
  variables. This matrix contains the only data used for the rest of
  this section.
\item All progress variables are checked for monotonicity with
  temperature in C++ code.
\item Monotonic progress variables are ranked by various algorithms.
\item If no monotonic progress variables exist, the progress variables
  are tested to pick the least non-monotonic option.
\item The best progress variable is sent to the table generation
  section.
\end{enumerate}

\subsection{Table Generation}
The table generation portion of our project is shown in
Fig.~\ref{fig:flow2}.  Inputs include the best progress variable from
the previous section and a text input file
containing the user\textquotesingle s selection of options to be used
at run time (same text input file from Fig.~\ref{fig:flow1}).  The
final output of this part of the code is a chemtable which is
visualized through contour plots.  Detailed descriptions of the
processes in Fig.~\ref{fig:flow2} are below.


\begin{enumerate}
\item This section of the program process the same FlameMaster data
  files used for progress variable selection. 
\item The progress variable is calculated for all rows in each data
  file and interpolated to find the value at the stoichiometric
  mixture fraction $C_{st}$.
\item The data files are sorted by the stoichiometric progress
  variable.
\item The progress variable is convoluted with PDFs.  The output is an
  array of values to be passed to the next process.
\item Numerical integration schemes are used in the convolution step.
\item These values are interpolated onto a grid as specified in the
  text input file.  This is the chemtable that is the final
  output of our program.
\end{enumerate}

\subsection{Implemented Routines}
As mentioned previously, many of the steps in both sections of the
program are implemented using polymorphic classes. For example,
specific interpolation methods are employed as classes which inherit
from an abstract interpolation class. Multiple integration methods,
sorting schemes, and PDFs are implemented in a similar manner. The
polymorphic classes that we use in our code are listed here.

\subsubsection{Sorting}
\begin{itemize}
\item “Brute” sort 
\item Bubble sort
\item C++ Standard Library Sort
\end{itemize}

\subsubsection{Integration}
\begin{itemize}
\item Trapezoidal method
\item Simpson\textquotesingle s rule
\item Gauss-Legendre quadrature
\end{itemize}

\subsubsection{Interpolation}
\begin{itemize}
\item Linear
\item Cubic spline
\item Cubic-Hermite interpolation
\end{itemize}

\subsubsection{Probability Density Function}
\begin{itemize}
\item Delta function
\item Beta distribution
\end{itemize}

\subsubsection{Slope Test}
\begin{itemize}
\item Average slope
\item Linear regression
\end{itemize}

\subsubsection{Least Nonmonotonicity Check}
\begin{itemize}
\item Simple check
\item Advanced check
\end{itemize}


\subsection{External Libraries}

We have used the following external libraries to facilitate the development of our
software:
\begin{itemize} 
\item C++ Standard Library - sorting
\item AlgLib - 
\item Matplotlib - contour plots of chemtable results
\item Numpy - matrix and vector calculations in Python
%\item SWIG - interface between Python and C++
\item numpy.i - SWIG typemapping
%\item FlameMaster (existing research software) - our code will not
%  interact with FlameMaster, but the data files (*.kg) generated by
%  FlameMaster will serve as inputs to our code
\end{itemize}

\subsection{SWIG Implementation}
C++ is interfaced with Python using SWIG, and the interface compiler
that connects C/C++ functions with scripting languages like Python,
Perl or Ruby. An example of how our C++ functions are wrapped is shown
in Fig.  \ref{fig:swig}. A *.i file was written for each abstract
class, which allows all derived classes to be called from Python. 
Compilation with SWIG generates *\_wrap.cxx, *.py and *.so
files. Generated shared objects can be imported into Python scripts.

\begin{figure} [h]
\centering
\includegraphics[width=0.7\textwidth]{python_swig_c++}
\caption{\label{fig:swig} Role of SWIG in the interface between Python
  and C++ as shown using the integrator class as an example.}
\end{figure}


\section{Versions}

\subsection{Prototype - 12/5/2014}
This version included at least one derived class per abstract
class. Each class worked independently. C++ code was compiled
separately and no Makefiles were submitted. A primitive Python demo
that read flamelet files, created candidate progress variables, and
plot progress variable against temperature was also included.
%\begin{itemize}
%\item Interface between functions (All)
%\item Interpolation routines (Daniel)
%\item Sorting algorithms (Emre, Jeffry)
%\item Monotonicity check and maximum slope tests (Bruce, Jeffry)
%\item Integration schemes (Emmet, Daniel)
%\item Probability density functions (Emmet)
%\item I/O text processing (Emre, Bruce)
%\end{itemize}
\\
\subsection{Alpha version - 12/12/2014}
This version included C++ code for at least one derived class per
abstract class. SWIG was used to create one module per derived
class. SWIG typecasting was done using standard vectors. All code was
compiled using separate Makefiles for each derived class, each called
by a single executable bash script. Python code interacted with a text
input file, called each module accordingly and printed out tabulated
data in the terminal.
%\begin{itemize}
%\item Preliminary Python wrapper will be implemented using SWIG and will allow for some %user interaction. (Emre, Emmet) 
%\item One routine from each step (1 interpolator, 1 sorting algorithm, the basic monotonicity %check, maximum slope check, 1 integration scheme along with 1 PDF) will be implemented %in C++. (All)
%\item The link between the progress variable selection and chemtable generation sections %will be implemented with Python. (Daniel, Jeffry)
%\item Fully-functional program that works on well-behaved data sets. (All)
%\item Basic plotting capability will be incorporated for visualization of the preliminary results.  %(Bruce)
%\end{itemize}

\subsection{Beta version - 01/15/2015}
All derived classes have been written. SWIG now generates one module
per abstract class. Python code interacts with a text input file, uses
full data sets, calls each module accordingly, prints out tabulated
data in a text file, and generates contour plots of the tabulated
data. All C++ and Python code have been tested using Python
Unittest. All files are organized in separate directories containing
source code, objects, modules, test functions, data, and output. All
code is now compiled from a single Makefile in the home
directory. Parallelization using OpenMP was implemented to reduce the
run time of the grid-fitting step.
%\begin{itemize}
%\item Fully-operational Python wrapper allows for autonomous and
%  interactive use.
%\item Based on the interface we will already have built for the alpha
%  function, we will implement alternative functions for
%  interpolation, least non-monotonicity checking, integration, PDFs,
%  and sorting.
%\item Fully-functional program that works on real FlameMaster output
%  data.
%\item Interactive and advanced plotting capabilities will be
%  incorporated for visualization.
%\item Error-checking functionality.
%\item Speed of key functions will be optimized.
%\end{itemize}

%For the beta version each team member will extend their own sections
% from the prototype %and alpha version.

\section{Division of Work and Git Repository Log}
Figures~\ref{fig:flow1} and~\ref{fig:flow2} show how C++/Python codes were
divided among the group. Each team member was responsible for testing
his own code. There were several other tasks completed by all team members:
\begin{itemize}
\item Swig interface files (*.i)
\item Test functions
\item Alpha version Makefiles
\item Design Document/Reports/Presentations
\end{itemize}
SWIG interface files were particularly challenging to write,
especially for our implementation (for abstract classes rather than
derived classes). As our project critically depended on making this
work, all team members spent large amounts of time learning SWIG for
the Alpha version. Specifically, Daniel made a breakthrough by
implementing numpy.i for type-recasting. This first appears in only
lininterp.i in the Alpha version, and was adopted for all SWIG
interface files for the Beta version. Emmet made a breakthrough in
generating modules for abstract classes, rather than generating
modules for derived classes. Again, this format was adapted by all for
the Beta version.

Other tasks were assigned to individual team members:
\begin{itemize}
\item Doxygen documentation: Emre
\item Beta version Makefiles: Emmet
\item Beta version README: Bruce
\end{itemize}

There are discrepancies between team members in the Git repository
commit log. We attribute this to various styles of using Git. Emmet
frequently committed minor changes to the repository, while Daniel and
Jeff committed larger sections of code more infrequently.

\section{Results}

The chemtable generation program has been successfully applied to two
data sets: a complete set of FlameMaster outputs for combustion of
C$_2$H$_4$, and a truncated subset of this data chosen to be a
well-behaved test case. These data sets were chosen to be
representative of real data that would be analyzed to make a chemtable
in turbulent combustion research. The input files used to run these
example cases are shown in Appendix A. Additionally, the outputs
printed by the program to the terminal when running these cases are
shown in Appendix B. Note that a warning is printed that the input
``plot all progress variables:'' has not been specified and the default
value, ``yes'', is being used.

Figure \ref{fig:xa_xb} shows the results of the progress variable
selection portion of the program, using the truncated and full data
sets. The species examined for inclusion in the progress variable are
H$_2$O, H$_2$, CO$_2$, and OH. For the truncated data case, almost all
candidate progress variables increase monotonically with temperature,
and the program selects the candidate with the maximum slope (Y-H2O +
Y-H2 + Y-CO2 + Y-OH). The program prints out this progress variable
and lists separately all other monotonic progress variables. For the
full case, all progress variables are non-monotonic, and the program
correctly identifies the lest non-monotonic progress variable (Y-H2O +
Y-H2 + Y-CO2). In fact, the non-monotonic region is small enough to be
indistinguishable in Fig. \ref{fig:xa_xb}(b). To notify the user, the
program issues a warning that no completely monotonic progress
variable was found.

\begin{figure} [h]
\centering
\includegraphics[width=\textwidth]{xa_xb.PNG}
\caption{\label{fig:xa_xb} Plots of the selected progress variable and
  other candidate progress variables as a function of temperature for
  the (a) truncated and (b) full data sets.  }
\end{figure}

Figure \ref{fig:ya_yb} shows sample contour plots generated from the
truncated and full data. The contour plot generated from the truncated
data matches what we expect for canonical counter-flow non-premixed
flames\footnote{Knudsen and Pitsch. Combust. Flame. (2009) vol. 156,
  pp. 678-696}. The contour plot for the full data set is
qualitatively similar, but has artifacts near where there are large
gradients in chemical source term. These artifacts are a result of the
slight non-monotonicity in the chosen progress variable and are
unavoidable. Overall, these plots show that the chemtable generation
program performs as expected and the data it produces is reliable.

\begin{figure} [h]
\centering
\includegraphics[width=\textwidth]{ya_yb.PNG}
\caption{\label{fig:ya_yb} Contour plots of chemical source term as a
  function of progress variable (C) and mixture fraction (Zmean) at
  Zvar = 0.02 for the (a) truncated and (b) full data sets.}
\end{figure}

\subsection{Profiling}
Our code was profiled using cProfile. For all cases, we used realistic
numbers of FlameMaster data files as well a grid sizes. The three
dimensions of the grid are Zmean, Zvar, and C. Zmean and Zvar refer
to the mean and variance of mixture fraction, $Z$.

Our results point to the grid-fitting step as the bottleneck in our
code. Results from tests with 201 grid points for Zmean and C, and
26 grid points for Zvar took the grid-fitting step 126 s to run and
the entire program 142 s. Grid-fitting performs two tasks, namely
interpolation and extrapolation. We attribute the long run times to
the extrapolation part of this function, which contains 5 nested for
loops. These for loops are necessary to search through a 3-dimensional
matrix, and then for each point, to search through the same matrix
again for the point’s nearest neighbor. Our only choice to speed up
this part of the code was through parallelizing these loops. We chose
to parallelize using OpenMP for its simplicity. Furthermore, even
after all future work is implemented (see Future Work section), our
expected run time should not exceed several hours. This run time is
negligible compared to any LES that will use these chemtables, so
parallelizing with MPI to use $>16$ nodes was deemed unnecessary.

Figure \ref{fig:fittogrid} shows run times using 1, 2, 4, and 8
threads. Again, grid sizes were taken to be 201 points for Zmean and
C, and 26 points for Zvar. For all cases, the total run time is about
16 s longer than the grid-fitting times. For 1, 2, and 4 threads used,
grid-fitting run times roughly decrease by half as the number of
threads doubles, indicating an $\mathcal{O}(n^{-1})$ dependence on
thread number, as expected. The times for 8 threads deviates from this
trends simply because the cost of parallelizing to 8 threads becomes
comparable to the speedup.

Figure \ref{fig:gridsensitivity} shows the scaling of run time with
the three dimensions of the grid. Based on the trends shown, it is
apparent that the run time scales quadratically with grid size for
Zmean and C, but linearly with grid size for Zvar. This behavior
matches with expectations based on the design of the program. In the
rate limiting grid fitting function, the nested loops must iterate
over Zmean and C twice, but only once over Zvar. This plot indicates
that higher grid resolution would significantly increase run time, but
the tested resolution is representative of what is required for
combustion research, so this should not be an issue.

\begin{figure} [h]
\centering
\includegraphics[width=0.6\textwidth]{plot_threads}
\caption{\label{fig:fittogrid} Comparison of run times for the
  gird-fitting function (FitToGrid) and total run time (CPU).}
\end{figure}

\begin{figure} [h]
\centering
\includegraphics[width=0.6\textwidth]{plot_gridsizes}
\caption{\label{fig:gridsensitivity} Sensitivity of parallelized code
  to grid size.}
\end{figure}

\subsection{Interpolator Accuracy}
The linear interpolation gave accurate results, but Hermite and cubic
interpolation scheme gave nonsensical results. An illustrative example
is shown in figure~\ref{fig:interpolator}. Steep gradients in the data
cause the interpolating polynomials to have steep gradients as well,
leading to the enormous inaccuracies observed. Linear interpolation
is, of course, insensitive to such effects. This leads us to question
the appropriateness of interpolation schemes which are susceptible to
such effects.

\begin{figure} [h]
\centering
\includegraphics[width=0.6\textwidth]{interpolator.PNG}
\caption{\label{fig:interpolator} Interpolating along a grid using
  cubic Hermite interpolation.}
\end{figure}

%\section{Future Work}
%Identifying a truly bijective mapping between progress variable and
% thermochemical state is among the most challenging and arbitrary
% parts of turbulent combustion simulations using flamelet
% models. This software greatly facilitates the progress variable
% selection process and will likely be used by researchers in the
% Computational Turbulent Reacting Flow Laboratory (CTRFL). While this
% software does meet all of our project objectives, there is future
% work to be done.

%\begin{itemize}
%\item Software should be extended to filter all chemical species
%  individually in addition to filtering chemical source terms as it
%  already does. Only filtered chemical source terms are needed to run
%  LES, but filtered species mass fractions and temperature are needed
%  for visualization of LES results.
%\item Mathematically rigorous algorithms for finding the least
%  non-monotonic progress variable can be incorporated based on current
%  mathematics research. For example, an index of
%  non-decreasingness\footnote{Qoyyimi \textit{et al.}, SSRN. (2014),
%    pp. 1-23.} can be implemented. Their applicability to progress
%  variable selection is, to date, unknown, but would be an interesting
%  topic of research.
%\item Manual selection of the best progress variable from a plot
%  generated at the end of the section shown in
%  Fig.~\ref{fig:flow1}. Currently, our program allows manual selection
%  of the best progress variable at the very beginning, where the user
%  is unable to view all the possible options.
%\end{itemize}

% We also think that the run time of our code may be an issue for large
% data sets and for the cases which require large number progress
% variable candidates. Also for our research purposes, the data sets
% that our program will deal with are considerably large. If time
% turns out to be a bigger issue, we may consider implementing
% multi-threading parallelization using OpenMP.

% Identifying a truly bijective mapping between progress variable and
% thermochemical state is among the most challenging and arbitrary
% parts of turbulent combustion simulations using flamelet
% models. Furthermore, even perfectly monotonic progress variables may
% have wildly varying slopes over temperature, so the highest average
% slope may not necessarily give the best progress variable. In fact,
% one may not even exist. For our project to be incorporated into real
% research codes it must still be able to deal with these challenging
% situations. In the worst cases, this can only be dealt with through
% plotting numerous graphs and requiring the user to visually
% determine the best progress variable. Regardless, our code will
% still greatly facilitate this process.

% Both sections of our project are independently useful. Even if one
% is not successful, our project will still provide a useful tool for
% turbulent combustion simulations. And due to the modular structure
% of our project, even if one component cannot be completed, the
% remaining portions will not be affected by this
% problem. Furthermore, the modular structure of our project allows us
% to develop the various components in parallel and iterate rapidly
% through versions of our code.

\section{Lessons Learned}
For most team members, this project was their first experience coding
collaboratively. This was no easy feat: version control and interface
design are particularly challenging in collaborative projects. We
benefited greatly from designing our interfaces early in the design
process and sticking to them. Using a Git repository greatly
facilitated sharing and debugging code.

This was also our first experience working on a project with so many
files. A project of this scale was difficult and confusing to maintain
for the Alpha version, and would have been even worse for the Beta
version had we not sorted our source code, modules, test, etc. into
different directories. Thus, we also learned the value of maintaining
a clean and organized working directory.

None of our team members had ever interfaced languages. This part of
the project was probably the most troublesome to get working. SWIG was
difficult to learn, but was incredibly useful. By interfacing C++ with
Python, we were able to handle IO text processing in Python, as well
as test our C++ code using Python Unittest.

\section{Conclusion/Future Work}
Identifying a truly bijective mapping between progress variable and
thermochemical state is among the most challenging and arbitrary parts
of turbulent combustion simulations using flamelet models. This
software greatly facilitates the progress variable selection process
and will likely be used by researchers in CTRFL. While this software
meets all of our project objectives, there remains future work that
could enhance the functionality and usability of this code:

\begin{itemize}
\item Software should be extended to filter all chemical species
  individually in addition to filtering chemical source terms as it
  already does. Only filtered chemical source terms are needed to run
  LES, but filtered species mass fractions and temperature are needed
  for visualization of LES results.
\item Mathematically rigorous algorithms for finding the least
  non-monotonic progress variable can be incorporated based on current
  mathematics research. For example, an index of
  non-decreasingness\footnote{Qoyyimi \textit{et al.}, SSRN. (2014),
    pp. 1-23.} can be implemented. Their applicability to progress
  variable selection is, to date, unknown, but would be an interesting
  topic of research.
\item Manual selection of the best progress variable from a plot
  generated at the end of the section shown in
  Fig.~\ref{fig:flow1}. Currently, our program allows manual selection
  of the best progress variable at the very beginning, where the user
  is unable to view all the possible options.
\end{itemize}


\clearpage
\section*{Appendix A: Input File}

The input file used to run the sample cases described in the Results
section is shown below. This input file is for the full case, but the
input file for the truncated case is identical except that “data/C2H4”
is replaced by “data/C2H4truncated”.

\vspace{12pt}


\hfill\begin{minipage}{\dimexpr\textwidth-3cm}
data file directory:	data/C2H4 \\
test species:	Y-H2O	Y-H2	Y-CO2	Y-OH \\
output file name:	data\_out \\
plot all progress variables:	\\
skip progress variable optimization:	no \\
extrapolate in fittogrid:	no \\
\\
number of threads:	4 \\
\\
Zmean\_grid:	201 \\
Zvar\_max:	0.25 \\ 
Zvar\_grid:	26 \\
\\
Zpdf:	beta \\
sort method:	standard \\
StoichMassFrac:	0.05 \\ 
interp method:	linear \\ 
max slope test:	linear regression \\
integrator:	trapezoid \\
least nonmonotonic check:	simple \\

glq Number of Nodes:	10 \\
length Cgrid:	201 \\

\xdef\tpd{\the\prevdepth}
\end{minipage}


\clearpage
\section*{Appendix B: Output}

Output for the full data case:
\vspace{12pt}


\hfill\begin{minipage}{\dimexpr\textwidth-3cm}

using default input for plot all progress variables:
['yes'] \\
Sorting PROGVARS by temperature using standard sort \\
Sorting FILESMATRIX by temperature \\
Testing monotonicity  \\
\\
Finding least non-monotonic progress variable using simple nonmono check \\
WARNING: no monotonic progress variables found, but proceeding with best alternative. \\
\\
The least non-monotonic progress variable is C = Y-H2O + Y-H2 + Y-CO2 \\ 
The column numbers of these species are [8, 7, 9] , respectively. \\
\\
\\
Sorting filesmatrix by C using standard sort\\
Generating PDF matrix with beta PDF\\
PDF calculated\\
Convoluting using trapezoid integration\\
Convolution completed\\
Maximum value of progress variable is: 0.162988071\\
Fitting final data to grid using linear interpolation\\
No extrapolation used to fit to grid\\
\\
Final data written to file: output/data\_out \\
10 contour plots created in output directory \\

\xdef\tpd{\the\prevdepth}
\end{minipage}

\vspace{12pt}


\newpage
Output for the truncated data case:
\vspace{12pt}

\hfill\begin{minipage}{\dimexpr\textwidth-3cm}


using default input for plot all progress variables:
['yes'] \\
Sorting PROGVARS by temperature using standard sort\\
Sorting FILESMATRIX by temperature\\
Testing monotonicity \\
\\
Testing max slope using linear regression\\
The chosen progress variable is C = Y-H2O + Y-H2 + Y-CO2 + Y-OH \\
The column numbers of these species are  [8, 7, 9, 6] , respectively.\\
\\
Other candidate monotonic progress variables are:\\
C = Y-H2O \\
C = Y-CO2 \\
C = Y-OH \\
C = Y-H2O + Y-H2 \\ 
C = Y-H2O + Y-CO2 \\
C = Y-H2O + Y-OH \\
C = Y-H2 + Y-CO2 \\
C = Y-H2 + Y-OH \\
C = Y-CO2 + Y-OH \\
C = Y-H2O + Y-H2 + Y-CO2 \\ 
C = Y-H2O + Y-H2 + Y-OH \\
C = Y-H2O + Y-CO2 + Y-OH \\
C = Y-H2 + Y-CO2 + Y-OH \\
\\
Sorting filesmatrix by C using standard sort\\
Generating PDF matrix with beta PDF\\
PDF calculated\\
Convoluting using trapezoid integration\\
Convolution completed\\
Maximum value of progress variable is: 0.050205925\\
Fitting final data to grid using linear interpolation\\
No extrapolation used to fit to grid\\
\\
Final data written to file: output/data\_out\\
10 contour plots created in output directory 

\xdef\tpd{\the\prevdepth}
\end{minipage}



\end{document}


 
